{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "mount_file_id": "1lSyCEkB0-DM0WRomOK3Ih2lldTFhsmag",
      "authorship_tag": "ABX9TyMcDcteYwdmIr6baT65PfO5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atlimited/llm_train/blob/main/deepseek.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXywgHLhQ-I8",
        "outputId": "4b25a237-b975-4598-b32d-b16939f4e193"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r deepseek\n",
        "!cp -r drive/MyDrive/deepseek ."
      ],
      "metadata": {
        "id": "j-HDHn29v5UA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "itI9bOMR84CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/train.txt ."
      ],
      "metadata": {
        "id": "k___LU02wh_3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4dmKbY1WADnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers.git -b v4.38.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvlyt6sLw18r",
        "outputId": "212fcbe2-464d-4454-a62e-a3f3cd912f92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp transformers/examples/pytorch/language-modeling/run_clm.py ."
      ],
      "metadata": {
        "id": "2pA6PPvryZvH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "an_bQYv9Pd6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiqB_rO1Uoc-",
        "outputId": "34485fcb-0914-43e7-e9f8-ad6e6e1dae86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deepseek  drive  output  run_clm.py  sample_data  train.txt  transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r transformers/examples/pytorch/language-modeling/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epPj8jx9YVo5",
        "outputId": "3b7ae640-cc64-4211-cccc-f2bcf003d2fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (0.29.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (2.2.1+cu121)\n",
            "Requirement already satisfied: datasets>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2.19.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.10/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 4)) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 6)) (0.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (3.9.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 6)) (0.18.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 7)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 7)) (3.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9BEyEhJYVvH",
        "outputId": "8d03273e-9c88-4d74-a727-a29a4209d177"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.10/dist-packages (2.5.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.2.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn) (24.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from flash-attn) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/deepseek/config.json\n",
        "\n",
        "{\n",
        "  \"architectures\": [\n",
        "    \"DeepseekForCausalLM\"\n",
        "  ],\n",
        "  \"attention_bias\": false,\n",
        "  \"attention_dropout\": 0.0,\n",
        "  \"auto_map\": {\n",
        "    \"AutoConfig\": \"configuration_deepseek.DeepseekConfig\",\n",
        "    \"AutoModel\": \"modeling_deepseek.DeepseekModel\",\n",
        "    \"AutoModelForCausalLM\": \"modeling_deepseek.DeepseekForCausalLM\"\n",
        "  },\n",
        "  \"bos_token_id\": 100000,\n",
        "  \"eos_token_id\": 100001,\n",
        "  \"first_k_dense_replace\": 1,\n",
        "  \"hidden_act\": \"silu\",\n",
        "  \"hidden_size\": 512,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 10944,\n",
        "  \"max_position_embeddings\": 4096,\n",
        "  \"model_type\": \"deepseek\",\n",
        "  \"moe_intermediate_size\": 1408,\n",
        "  \"moe_layer_freq\": 1,\n",
        "  \"n_routed_experts\": 8,\n",
        "  \"n_shared_experts\": 2,\n",
        "  \"norm_topk_prob\": false,\n",
        "  \"num_attention_heads\": 16,\n",
        "  \"num_experts_per_tok\": 6,\n",
        "  \"num_hidden_layers\": 14,\n",
        "  \"num_key_value_heads\": 16,\n",
        "  \"pretraining_tp\": 1,\n",
        "  \"rms_norm_eps\": 1e-06,\n",
        "  \"rope_scaling\": null,\n",
        "  \"rope_theta\": 10000,\n",
        "  \"scoring_func\": \"softmax\",\n",
        "  \"tie_word_embeddings\": false,\n",
        "  \"torch_dtype\": \"bfloat16\",\n",
        "  \"transformers_version\": \"4.36.0\",\n",
        "  \"use_cache\": true,\n",
        "  \"vocab_size\": 102400\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ONdNbUg435T",
        "outputId": "978a4999-577d-4f04-8f2e-6cae4c52ddd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/deepseek/config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from deepseek.modeling_deepseek import DeepseekForCausalLM\n",
        "from deepseek.configuration_deepseek import DeepseekConfig\n",
        "\n",
        "model_dir = 'deepseek'\n",
        "config_file = './deepseek/config.json'\n",
        "with open(config_file, 'r') as f:\n",
        "    config = json.load(f)\n",
        "    config = DeepseekConfig.from_dict(config)\n",
        "\n",
        "model = DeepseekForCausalLM(config)\n",
        "\n",
        "model.save_pretrained(model_dir)"
      ],
      "metadata": {
        "id": "wlxl57T-0oLM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_clm.py \\\n",
        "    --model_name_or_path=./deepseek \\\n",
        "    --train_file=train.txt \\\n",
        "    --validation_file=train.txt \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --num_train_epochs=30 \\\n",
        "    --save_steps=10000 \\\n",
        "    --save_total_limit=3 \\\n",
        "    --per_device_train_batch_size=1 \\\n",
        "    --per_device_eval_batch_size=1 \\\n",
        "    --output_dir=output/ \\\n",
        "    --overwrite_output_dir=true \\\n",
        "    --use_fast_tokenizer=False \\\n",
        "    --trust_remote_code=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORvTha_jyoy7",
        "outputId": "88e75a30-ae39-497e-c016-f7bfcf45c6f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-22 04:15:03.443065: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-22 04:15:03.443113: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-22 04:15:03.444806: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-22 04:15:04.677193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "04/22/2024 04:15:07 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "04/22/2024 04:15:07 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/runs/Apr22_04-15-07_760028fc9b50,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=30.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=output/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=10000,\n",
            "save_strategy=steps,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "Using custom data configuration default-51a4de944247d940\n",
            "04/22/2024 04:15:07 - INFO - datasets.builder - Using custom data configuration default-51a4de944247d940\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/text\n",
            "04/22/2024 04:15:07 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/text\n",
            "Generating dataset text (/root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101)\n",
            "04/22/2024 04:15:07 - INFO - datasets.builder - Generating dataset text (/root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101)\n",
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101...\n",
            "04/22/2024 04:15:07 - INFO - datasets.builder - Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101...\n",
            "Downloading took 0.0 min\n",
            "04/22/2024 04:15:07 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "Checksum Computation took 0.0 min\n",
            "04/22/2024 04:15:07 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Generating train split\n",
            "04/22/2024 04:15:07 - INFO - datasets.builder - Generating train split\n",
            "Generating train split: 5135 examples [00:00, 491583.57 examples/s]\n",
            "Generating validation split\n",
            "04/22/2024 04:15:07 - INFO - datasets.builder - Generating validation split\n",
            "Generating validation split: 5135 examples [00:00, 879414.93 examples/s]\n",
            "Unable to verify splits sizes.\n",
            "04/22/2024 04:15:07 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101. Subsequent calls will reuse this data.\n",
            "04/22/2024 04:15:07 - INFO - datasets.builder - Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101. Subsequent calls will reuse this data.\n",
            "[INFO|configuration_utils.py:726] 2024-04-22 04:15:07,989 >> loading configuration file ./deepseek/config.json\n",
            "[INFO|configuration_utils.py:726] 2024-04-22 04:15:07,992 >> loading configuration file ./deepseek/config.json\n",
            "[INFO|configuration_utils.py:791] 2024-04-22 04:15:07,993 >> Model config DeepseekConfig {\n",
            "  \"_name_or_path\": \"./deepseek\",\n",
            "  \"architectures\": [\n",
            "    \"DeepseekForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"configuration_deepseek.DeepseekConfig\",\n",
            "    \"AutoModel\": \"modeling_deepseek.DeepseekModel\",\n",
            "    \"AutoModelForCausalLM\": \"modeling_deepseek.DeepseekForCausalLM\"\n",
            "  },\n",
            "  \"aux_loss_alpha\": 0.001,\n",
            "  \"bos_token_id\": 100000,\n",
            "  \"eos_token_id\": 100001,\n",
            "  \"first_k_dense_replace\": 1,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 512,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 10944,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"deepseek\",\n",
            "  \"moe_intermediate_size\": 1408,\n",
            "  \"moe_layer_freq\": 1,\n",
            "  \"n_routed_experts\": 8,\n",
            "  \"n_shared_experts\": 2,\n",
            "  \"norm_topk_prob\": false,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_experts_per_tok\": 6,\n",
            "  \"num_hidden_layers\": 14,\n",
            "  \"num_key_value_heads\": 16,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000,\n",
            "  \"scoring_func\": \"softmax\",\n",
            "  \"seq_aux\": true,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 102400\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2044] 2024-04-22 04:15:07,995 >> loading file tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:2044] 2024-04-22 04:15:07,995 >> loading file tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2044] 2024-04-22 04:15:07,995 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:2044] 2024-04-22 04:15:07,995 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2044] 2024-04-22 04:15:07,995 >> loading file tokenizer_config.json\n",
            "[WARNING|logging.py:314] 2024-04-22 04:15:08,244 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|modeling_utils.py:3254] 2024-04-22 04:15:08,268 >> loading weights file ./deepseek/model.safetensors\n",
            "[INFO|configuration_utils.py:845] 2024-04-22 04:15:08,285 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 100000,\n",
            "  \"eos_token_id\": 100001\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:3992] 2024-04-22 04:15:08,661 >> All model checkpoint weights were used when initializing DeepseekForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4000] 2024-04-22 04:15:08,661 >> All the weights of DeepseekForCausalLM were initialized from the model checkpoint at ./deepseek.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DeepseekForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:798] 2024-04-22 04:15:08,666 >> loading configuration file ./deepseek/generation_config.json\n",
            "[INFO|configuration_utils.py:845] 2024-04-22 04:15:08,666 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 100000,\n",
            "  \"eos_token_id\": 100001\n",
            "}\n",
            "\n",
            "Running tokenizer on dataset:   0% 0/5135 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-9b609e1b34c968fa.arrow\n",
            "04/22/2024 04:15:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-9b609e1b34c968fa.arrow\n",
            "Running tokenizer on dataset: 100% 5135/5135 [00:00<00:00, 19385.95 examples/s]\n",
            "Running tokenizer on dataset:   0% 0/5135 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-bc88b6aa25878952.arrow\n",
            "04/22/2024 04:15:09 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-bc88b6aa25878952.arrow\n",
            "Running tokenizer on dataset: 100% 5135/5135 [00:00<00:00, 24511.04 examples/s]\n",
            "04/22/2024 04:15:09 - WARNING - __main__ - The tokenizer picked seems to have a very large `model_max_length` (16384). Using block_size=1024 instead. You can change that default value by passing --block_size xxx.\n",
            "Grouping texts in chunks of 1024:   0% 0/5135 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-5602e91bda3e8c0d.arrow\n",
            "04/22/2024 04:15:09 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-5602e91bda3e8c0d.arrow\n",
            "Grouping texts in chunks of 1024: 100% 5135/5135 [00:00<00:00, 12308.60 examples/s]\n",
            "Grouping texts in chunks of 1024:   0% 0/5135 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-268037b88ebe8e0e.arrow\n",
            "04/22/2024 04:15:09 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-51a4de944247d940/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-268037b88ebe8e0e.arrow\n",
            "Grouping texts in chunks of 1024: 100% 5135/5135 [00:00<00:00, 11697.49 examples/s]\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1812] 2024-04-22 04:15:11,598 >> ***** Running training *****\n",
            "[INFO|trainer.py:1813] 2024-04-22 04:15:11,598 >>   Num examples = 308\n",
            "[INFO|trainer.py:1814] 2024-04-22 04:15:11,598 >>   Num Epochs = 30\n",
            "[INFO|trainer.py:1815] 2024-04-22 04:15:11,598 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1818] 2024-04-22 04:15:11,598 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1819] 2024-04-22 04:15:11,598 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1820] 2024-04-22 04:15:11,598 >>   Total optimization steps = 9,240\n",
            "[INFO|trainer.py:1821] 2024-04-22 04:15:11,600 >>   Number of trainable parameters = 417,565,184\n",
            "  0% 10/9240 [00:05<1:21:55,  1.88it/s]Traceback (most recent call last):\n",
            "  File \"/content/run_clm.py\", line 670, in <module>\n",
            "    main()\n",
            "  File \"/content/run_clm.py\", line 618, in main\n",
            "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 1624, in train\n",
            "    return inner_training_loop(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 1928, in _inner_training_loop\n",
            "    for step, inputs in enumerate(epoch_iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\", line 461, in __iter__\n",
            "    current_batch = send_to_device(current_batch, self.device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 189, in send_to_device\n",
            "    {\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 190, in <dictcomp>\n",
            "    k: t if k in skip_keys else send_to_device(t, device, non_blocking=non_blocking, skip_keys=skip_keys)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 158, in send_to_device\n",
            "    return tensor.to(device, non_blocking=non_blocking)\n",
            "KeyboardInterrupt\n",
            "  0% 10/9240 [00:06<1:36:44,  1.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wo6ksxI5n2dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FkPlZVrOn2iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6IC_L8gn2ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LL9cFuvOn2oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7S7bNDHn2qh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}